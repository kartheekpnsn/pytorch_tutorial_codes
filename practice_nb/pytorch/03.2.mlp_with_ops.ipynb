{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = os.cpu_count()\n",
    "print(f\"Number of workers: {num_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = datasets.load_wine()\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X.astype(np.float32))\n",
    "y = torch.from_numpy(y.astype(np.int64))\n",
    "# y = y.view(y.shape[0], 1)\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, stratify=y_train, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LRDataset(X_train, y_train)\n",
    "val_ds = LRDataset(X_val, y_val)\n",
    "test_ds = LRDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_ds, batch_size=32, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    dataset=val_ds, batch_size=32, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    dataset=test_ds, batch_size=32, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, dropout_prob=0.3):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_features, 32),\n",
    "            nn.BatchNorm1d(32),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(16, 8),\n",
    "            nn.BatchNorm1d(8),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(8, n_classes),  # Output layer (no activation for logits)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Model and Define Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImprovedMLP(n_features=n_features, n_classes=3).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLOpsHandler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        log_dir=\"../../runs/mlp_ops\",\n",
    "        model_save_dir=\"../../runs/models\",\n",
    "        experiment_name=\"MLP_Experiment\",\n",
    "    ):\n",
    "        self.writer = SummaryWriter(log_dir=log_dir)\n",
    "        self.model_save_dir = model_save_dir\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize MLFlow\n",
    "        os.makedirs(f\"{log_dir}/mlruns\", exist_ok=True)\n",
    "        mlflow.set_tracking_uri(f\"{log_dir}/mlruns\")\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        self.run = mlflow.start_run()\n",
    "\n",
    "    def log_metrics(self, metrics, epoch):\n",
    "        \"\"\"Logs metrics to TensorBoard and MLFlow.\"\"\"\n",
    "        for key, value in metrics.items():\n",
    "            self.writer.add_scalar(key, value, epoch)\n",
    "            mlflow.log_metric(key, value, step=epoch)\n",
    "\n",
    "    def log_hyperparameters(self, params):\n",
    "        \"\"\"Logs hyperparameters to MLFlow.\"\"\"\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    def save_model(self, model, epoch):\n",
    "        \"\"\"Saves the model checkpoint and logs it to MLFlow.\"\"\"\n",
    "        model_path = os.path.join(self.model_save_dir, f\"model_epoch_{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        mlflow.pytorch.log_model(model, artifact_path=f\"model_epoch_{epoch}\")\n",
    "\n",
    "    def load_model(self, model, model_path):\n",
    "        \"\"\"Loads a model checkpoint.\"\"\"\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the TensorBoard writer and MLFlow run.\"\"\"\n",
    "        self.writer.close()\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlops_handler = MLOpsHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 5\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        # Move data to device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_dl)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # Validation loss calculation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_val_batch, y_val_batch in val_dl:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            y_val_pred = model(X_val_batch)\n",
    "            val_loss += loss_fn(y_val_pred, y_val_batch).item()\n",
    "\n",
    "        val_loss /= len(val_dl)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    mlops_handler.log_metrics({\"train_loss\": epoch_loss, \"val_loss\": val_loss}, epoch)\n",
    "    if verbose and (epoch + 1) % verbose == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{n_epochs} | Training Loss: {epoch_loss:.4f} | Validation Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "        mlops_handler.save_model(model, epoch)\n",
    "\n",
    "print(f\"Final Training Loss: {epoch_loss:.4f} | Validation Loss: {val_loss:.4f}\")\n",
    "mlops_handler.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
