{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers: 16\n"
     ]
    }
   ],
   "source": [
    "num_workers = os.cpu_count()\n",
    "print(f\"Number of workers: {num_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = datasets.load_wine()\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X.astype(np.float32))\n",
    "y = torch.from_numpy(y.astype(np.int64))\n",
    "# y = y.view(y.shape[0], 1)\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([113, 13]), torch.Size([29, 13]), torch.Size([36, 13]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, stratify=y_train, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LRDataset(X_train, y_train)\n",
    "val_ds = LRDataset(X_val, y_val)\n",
    "test_ds = LRDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_ds, batch_size=32, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    dataset=val_ds, batch_size=32, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    dataset=test_ds, batch_size=32, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(n_features, 16)\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.linear3 = nn.Linear(8, 4)\n",
    "        self.linear4 = nn.Linear(4, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.linear1(x))\n",
    "        out = self.relu(self.linear2(out))\n",
    "        out = self.relu(self.linear3(out))\n",
    "        out = self.linear4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPSequential(nn.Module):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(MLPSequential, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_features, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDict(nn.Module):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(MLPDict, self).__init__()\n",
    "        self.layers = nn.ModuleDict(\n",
    "            {\n",
    "                \"linear1\": nn.Linear(n_features, 16),\n",
    "                \"relu1\": nn.ReLU(),\n",
    "                \"linear2\": nn.Linear(16, 8),\n",
    "                \"relu2\": nn.ReLU(),\n",
    "                \"linear3\": nn.Linear(8, 4),\n",
    "                \"relu3\": nn.ReLU(),\n",
    "                \"linear4\": nn.Linear(4, n_classes),  # No activation here\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers[\"relu1\"](self.layers[\"linear1\"](x))\n",
    "        x = self.layers[\"relu2\"](self.layers[\"linear2\"](x))\n",
    "        x = self.layers[\"relu3\"](self.layers[\"linear3\"](x))\n",
    "        x = self.layers[\"linear4\"](x)  # No activation here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, dropout_prob=0.3):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_features, 32),\n",
    "            nn.BatchNorm1d(32),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(16, 8),\n",
    "            nn.BatchNorm1d(8),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(8, n_classes),  # Output layer (no activation for logits)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Model and Define Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImprovedMLP(n_features=n_features, n_classes=3).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"../../runs/mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 5\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ab8203bd054e19bcf0feec3e58ed68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Training Loss: 0.8230 | Validation Loss: 0.7369\n",
      "Epoch 10/100 | Training Loss: 0.6941 | Validation Loss: 0.6809\n",
      "Epoch 15/100 | Training Loss: 0.6412 | Validation Loss: 0.9672\n",
      "Epoch 20/100 | Training Loss: 0.5505 | Validation Loss: 0.5552\n",
      "Epoch 25/100 | Training Loss: 0.4821 | Validation Loss: 0.4061\n",
      "Epoch 30/100 | Training Loss: 0.3709 | Validation Loss: 0.3464\n",
      "Epoch 35/100 | Training Loss: 0.4447 | Validation Loss: 0.7510\n",
      "Epoch 40/100 | Training Loss: 0.4030 | Validation Loss: 1.4630\n",
      "Epoch 45/100 | Training Loss: 0.3261 | Validation Loss: 0.1573\n",
      "Epoch 50/100 | Training Loss: 0.3382 | Validation Loss: 0.1091\n",
      "Epoch 55/100 | Training Loss: 0.2313 | Validation Loss: 0.1240\n",
      "Epoch 60/100 | Training Loss: 0.2730 | Validation Loss: 0.1185\n",
      "Epoch 65/100 | Training Loss: 0.2669 | Validation Loss: 0.0640\n",
      "Epoch 70/100 | Training Loss: 0.2845 | Validation Loss: 0.1252\n",
      "Epoch 75/100 | Training Loss: 0.2118 | Validation Loss: 0.0498\n",
      "Epoch 80/100 | Training Loss: 0.3696 | Validation Loss: 0.6474\n",
      "Epoch 85/100 | Training Loss: 0.2349 | Validation Loss: 0.1481\n",
      "Epoch 90/100 | Training Loss: 0.2434 | Validation Loss: 0.2639\n",
      "Epoch 95/100 | Training Loss: 0.2911 | Validation Loss: 0.0626\n",
      "Epoch 100/100 | Training Loss: 0.2633 | Validation Loss: 0.1487\n",
      "Final Training Loss: 0.2633 | Validation Loss: 0.1487\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_dl:\n",
    "        # Move data to device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_dl)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # Validation loss calculation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_val_batch, y_val_batch in val_dl:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            y_val_pred = model(X_val_batch)\n",
    "            val_loss += loss_fn(y_val_pred, y_val_batch).item()\n",
    "\n",
    "        val_loss /= len(val_dl)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    writer.add_scalars(\"Loss\", {\"Train\": epoch_loss, \"Validation\": val_loss}, epoch)\n",
    "    if verbose and (epoch + 1) % verbose == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{n_epochs} | Training Loss: {epoch_loss:.4f} | Validation Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "print(f\"Final Training Loss: {epoch_loss:.4f} | Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
